---
layout: publication
title: "Deep Surface Reconstruction from Point Clouds with Visibility Information"
image: assets/img/publications/2022_dsrv/2022_dsrv_teaser.png
hide: false
category: [3d-reconstruction, 3d-perception]
authors: Raphael Sulzer, Loic Landrieu, Alexandre Boulch, Renaud Marlet and Bruno Vallet
venue: ICPR
venue_long: International Conference on Pattern Recognition
year: 2022
month: 8
code_url: https://github.com/raphaelsulzer/dsrv-data
paper_url: https://arxiv.org/abs/2202.01810
blog_url:
slides_url:
bib_url:
permalink: /publications/dsrv/
---

<h1 align="center"> {{page.title}} </h1>
<h3 align="center">  <a href="https://raphaelsulzer.de/">Raphael Sulzer</a>&nbsp;&nbsp;<a href="https://loiclandrieu.com/">Loic Landrieu</a>&nbsp;&nbsp;<a href="https://boulch.eu/">Alexandre Boulch</a>&nbsp;&nbsp;<a href="http://imagine.enpc.fr/~marletr/">Renaud Marlet</a>&nbsp;&nbsp;<a href="https://www.umr-lastig.fr/bruno-vallet/">Bruno Vallet</a></h3>


<h3 align="center"> {{page.venue}} {{page.year}} </h3>

<div align="center">
  <p>
    {% if page.paper_url %}
    <a href="{{ page.paper_url }}"><i class="far fa-file-pdf"></i> Paper</a>&nbsp;&nbsp;
    {% endif %}
    {% if page.code_url %}
    <a href="{{ page.code_url }}"><i class="fab fa-github"></i> Code</a> &nbsp;&nbsp;
    {% endif %}
    {% if page.blog_url %}
    <a href="{{ page.blog_url }}"><i class="fab fa-blogger"></i> Blog</a> &nbsp;&nbsp;
    {% endif %}
    {% if page.slides_url %}
    <a href="{{ page.slides_url }}"><i class="far fa-file-pdf"></i> Slides</a>&nbsp;&nbsp;
    {% endif %}
    {% if page.bib_url %}
    <a href="{{ page.bib_url}}"><i class="far fa-file-alt"></i> BibTeX</a>&nbsp;&nbsp;
    {% endif %}
  </p>
</div>


![](../../assets/img/publications/2022_dsrv/2022_dsrv_teaser.png){:width="100%"}

<hr>

<h2  align="center"> Abstract</h2>

<p align="justify">Most current neural networks for reconstructing surfaces from point clouds ignore sensor poses and only operate on raw point locations. Sensor visibility, however, holds meaningful information regarding space occupancy and surface orientation. In this paper, we present two simple ways to augment raw point clouds with visibility information, so it can directly be leveraged by surface reconstruction networks with minimal adaptation. Our proposed modifications consistently improve the accuracy of generated surfaces as well as the generalization ability of the networks to unseen shape domains.
</a></p>

<br>

<hr>

<h2  align="center">BibTeX</h2>
<left>
  <pre class="bibtex-box">
@inproceedings{sulzer2022deep,
  title={Deep surface reconstruction from point clouds with visibility information},
  author={Sulzer, Raphael and Landrieu, Loic and Boulch, Alexandre and Marlet, Renaud and Vallet, Bruno},
  booktitle={2022 26th International Conference on Pattern Recognition (ICPR)},
  pages={2415--2422},
  year={2022},
  organization={IEEE}
}
</pre>
</left>

<br>
