<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content=""/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>UNIT: unsupervised Online Instance Segmentation through Time | valeo.ai - valeo.ai research page</title> <meta name="author" content=" "/> <meta name="description" content="valeo.ai research page "/> <meta name="keywords" content="computer vision, ai, valeo, artificial intelligence, research, deep learning"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/valeoai_logo_256x256.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://valeoai.github.io//publications/unit/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"> <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script> <script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"[%",right:"%]",display:!0},{left:"$",right:"$",display:!1}]})});</script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><img src="/assets/img/valeoai_logo.png" alt="valeo.ai" class="title-logo" height="24px"></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/"></a> </li> <li class="nav-item "> <a class="nav-link" href="/team/">Team</a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Code &amp; Data</a> </li> <li class="nav-item "> <a class="nav-link" href="/posts/">Posts</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="publication"> <style>.container{max-width:1200px}table{border-collapse:collapse;width:100%}table th,table td{border:1px solid black;padding:8px;text-align:center;padding:0 .2em 0 .2em}.online-column{width:50px;border-left:0;border-right:0;font-size:20px}.checkmark{color:green}.crossmark{color:red}.highlightrow{background-color:color-mix(in srgb,var(--global-theme-color) 15%,transparent)}</style> <h1 align="center"> UNIT: unsupervised Online Instance Segmentation through Time </h1> <h3 align="center"> <a href="https://csautier.github.io/" target="_blank" rel="noopener noreferrer">Corentin Sautier</a>   <a href="https://sites.google.com/site/puygilles/home" target="_blank" rel="noopener noreferrer">Gilles Puy</a>    <a href="https://www.boulch.eu/" target="_blank" rel="noopener noreferrer">Alexandre Boulch</a>   <a href="http://imagine.enpc.fr/~marletr" target="_blank" rel="noopener noreferrer">Renaud Marlet</a>   <a href="https://vincentlepetit.github.io/" target="_blank" rel="noopener noreferrer">Vincent Lepetit</a> </h3> <h3 align="center"> 3DV 2025 </h3> <div align="center"> <p> <a href="https://arxiv.org/abs/2409.07887" target="_blank" rel="noopener noreferrer"><i class="far fa-file-pdf"></i> Paper</a>   <a href="https://github.com/valeoai/UNIT" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i> Code</a>    </p> </div> <hr> <h2 align="center"> Abstract</h2> <p align="justify">Online object segmentation and tracking in Lidar point clouds enables autonomous agents to understand their surroundings and make safe decisions. Unfortunately, manual annotations for these tasks are prohibitively costly. We tackle this problem with the task of class-agnostic unsupervised online instance segmentation and tracking. To that end, we leverage an instance segmentation backbone and propose a new training recipe that enables the online tracking of objects. Our network is trained on pseudo-labels, eliminating the need for manual annotations. We conduct an evaluation using metrics adapted for temporal instance segmentation. Computing these metrics requires temporally-consistent instance labels. When unavailable, we construct these labels using the available 3D bounding boxes and semantic labels in the dataset. We compare our method against strong baselines and demonstrate its superiority across two different outdoor Lidar datasets.</p> <hr> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="padding-right: 5px;padding-left: 5px;"> <img src="../../assets/img/publications/2024_unit/SEGTARL.jpg" class="img-fluid zoomable-image rounded z-depth-1"> <div class="caption"> TARL segments [1] </div> </div> <div class="col-sm mt-3 mt-md-0" style="padding-right: 5px;padding-left: 5px;"> <img src="../../assets/img/publications/2024_unit/Seg4D.jpg" class="img-fluid zoomable-image rounded z-depth-1"> <div class="caption"> 4D-Seg (Ours) </div> </div> <div class="col-sm mt-3 mt-md-0" style="padding-right: 5px;padding-left: 5px;"> <img src="../../assets/img/publications/2024_unit/UNIT.jpg" class="img-fluid zoomable-image rounded z-depth-1"> <div class="caption"> UNIT (Ours) </div> </div> <div class="col-sm mt-3 mt-md-0" style="padding-right: 5px;padding-left: 5px;"> <img src="../../assets/img/publications/2024_unit/GT.jpg" class="img-fluid zoomable-image rounded z-depth-1"> <div class="caption"> Ground truth </div> </div> </div> <p>We generate pseudo-labels of instances across time in Lidar scans (4D-Seg), which we use to train an online segmenter (UNIT) that assigns to each 3D point an instance ID consistent over time. We show aggregations of scans over time. This sample scene if from SemanticKITTI, and the car in the foreground is static. The first two images show two prior baselines for this task. Image 3 is shows our input pseudo-labels. The fourth image renders an aggregation of UNIT on successive scans (our input is not an aggregated scan). Note that we obtain more labels than in the ground truth as our class-agnostic segmentation include all objects and stuff, such as trees or buildings.</p> <div class="rendering"> <iframe src="../../assets/other/potree/rendering.html?data-path=./pointclouds/rendering/cloud.json" width="100%" height="500px" frameborder="0"></iframe> <div class="caption"> Instance segmentation of UNIT on aggregated frames, validation set of SemanticKITTI. Moving objects appear elongated in world coordinates aggregated scans. </div> </div> <object type="image/svg+xml" data="../../assets/img/publications/2024_unit/method_overview_nolatex.svg" width="100%"> <iframe src="../../assets/img/projects/publications/2024_unit/method_overview_nolatex.svg" width="100%" frameborder="0"></iframe> Your browser does not support SVG </object> <div class="caption"> Method overview. Given unlabeled Lidar scans, we create offline pseudo-labels by spatio-temporal clustering (preprocessing). We then use these pseudo-labels to train an auto-regressive network. At inference, we apply this network to successive scans as they come. </div> <table> <thead> <tr> <th rowspan="2">Semantic KITTI</th> <th class="online-column" rowspan="2">Online</th> <th colspan="3">Unfiltered</th> <th colspan="2">Filtered</th> </tr> <tr> <th>$$\mathrm{S_{assoc}^{temp}}$$</th> <th>$$\mathrm{IoU^*}$$</th> <th>$$\mathrm{S_{assoc}}$$</th> <th>$$\mathrm{S_{assoc}^{temp}}$$</th> <th>$$\mathrm{S_{assoc}}$$</th> </tr> </thead> <tbody> <tr> <td>3DUIS w/o time [2]</td> <td class="online-column checkmark">✔</td> <td>-</td> <td>-</td> <td>0.550</td> <td>-</td> <td>0.768</td> </tr> <tr class="highlightrow"> <td>UNIT w/o time</td> <td class="online-column checkmark">✔</td> <td>-</td> <td>-</td> <td><strong>0.715</strong></td> <td>-</td> <td><strong>0.811</strong></td> </tr> <tr> <td>3DUIS++</td> <td class="online-column checkmark">✔</td> <td>0.116</td> <td>0.214</td> <td>0.550</td> <td>0.148</td> <td>0.769</td> </tr> <tr> <td>TARL-Seg [1]</td> <td class="online-column crossmark">✘</td> <td>0.231</td> <td>0.353</td> <td>0.668</td> <td>0.264</td> <td>0.735</td> </tr> <tr> <td>TARL-Seg++</td> <td class="online-column checkmark">✔</td> <td>0.317</td> <td>0.446</td> <td>0.617</td> <td>0.370</td> <td>0.678</td> </tr> <tr> <td>4D-Seg</td> <td class="online-column crossmark">✘</td> <td>0.421</td> <td>0.529</td> <td>0.667</td> <td>0.486</td> <td>0.784</td> </tr> <tr> <td>4D-Seg++</td> <td class="online-column checkmark">✔</td> <td>0.447</td> <td>0.513</td> <td>0.647</td> <td>0.512</td> <td>0.762</td> </tr> <tr class="highlightrow"> <td>UNIT</td> <td class="online-column checkmark">✔</td> <td><strong>0.482</strong></td> <td><strong>0.568</strong></td> <td>0.696</td> <td><strong>0.563</strong></td> <td>0.790</td> </tr> </tbody> </table> <div class="caption" style="padding-top: 1em"> Results on SemanticKITTI. All scores are computed on the validation set of SemanticKITTI. The "filtered" scores are computed on segments of more than 50 points for any given scan as reported by prior art. Information about the metrics, and more datasets are available in the paper. </div> <h2 align="center">BibTeX</h2> <left> <pre class="bibtex-box">
  @inproceedings{sautier2025unit,
    title = {{UNIT}: Unsupervised Online Instance Segmentation through Time},
    author = {Corentin Sautier and Gilles Puy and Alexandre Boulch and Renaud Marlet and Vincent Lepetit},
    booktitle= {3DV},
    year = {2025}
  }</pre> </left> <p><br></p> <h2 align="center"> Sources</h2> <p>[1] Nunes et al. “Temporal consistent 3D lidar representation learning for semantic perception in autonomous driving.” <i>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.</i> 2023.</p> <p>[2] Nunes et al. “Unsupervised Class-Agnostic Instance Segmentation of 3D LiDAR Data for Autonomous Vehicles.” <i>IEEE Robotics and Automation Letters (RA-L).</i> 2022.</p> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container">valeo.ai research page </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> </body> </html>